{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Model validation.\n",
    "`Measuring model quality is a key to iteratively improving your models.`\n",
    "\n",
    "I'll want to evaluate almost every model that I ever build. In other words, will the model's predictions be close to what actually happens.\n",
    "Many people make a hudge misteke when measuring predictive accuracy.\n",
    "You'd first need to summarize the model quality into an understandable way. If comparing actual and predictive values for 10000 houses, you'll likely find mix of good and bad predictions. Looking thorough a list of 10000 predicted and actual values would be pointless. We need to summarize this into a single metric.\n",
    "\n",
    "There many metrics to summarize model quality, one of them is a `MAE` (Mean absolute Error).\n",
    "\n",
    "**The prediction error for each house is:**  \n",
    "`error = actual - predicted`  \n",
    "So, if house's price 150,000 USD, and you predicted it would cost 100,000 the error is 50,000.\n",
    "\n",
    "With the MAE, we take the absolute value of each error (this converts each error to a positive number). We then take the average of those absolute errors. This is our measure of model quality.  \n",
    "`In plain English, it can be said as`\n",
    "> On average, our predictions  are off by about X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The example from: 003_1_first_machine_learning_model.***\n",
    "```Python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, predictions)\n",
    "\n",
    ">>> 30642.671232876713\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n",
      "\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "iowa_file_path = './data/home_data_for_machine_learning/train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "y = home_data.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "# Fit Model\n",
    "iowa_model.fit(X, y)\n",
    "\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())\n",
    "\n",
    "print('\\nComplete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw attention**\n",
    "```Python\n",
    "Syntax: Series.tolist()\n",
    "\n",
    "Return type: Converted series into List\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "### Step 1: Split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BaseCrossValidator', 'GridSearchCV', 'GroupKFold', 'GroupShuffleSplit', 'KFold', 'LeaveOneGroupOut', 'LeaveOneOut', 'LeavePGroupsOut', 'LeavePOut', 'ParameterGrid', 'ParameterSampler', 'PredefinedSplit', 'RandomizedSearchCV', 'RepeatedKFold', 'RepeatedStratifiedKFold', 'ShuffleSplit', 'StratifiedKFold', 'StratifiedShuffleSplit', 'TimeSeriesSplit', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_search', '_split', '_validation', 'check_cv', 'cross_val_predict', 'cross_val_score', 'cross_validate', 'fit_grid_point', 'learning_curve', 'permutation_test_score', 'train_test_split', 'validation_curve']\n"
     ]
    }
   ],
   "source": [
    "print(dir(sklearn.model_selection ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `train_test_split` function\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fill in\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 7)\n",
      "(1095,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 7)\n",
      "(365,)\n"
     ]
    }
   ],
   "source": [
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Specify and Fit model  \n",
    "\n",
    "Create a `Decision Tree Regressor` model and `fit it to the relevant data`.  \n",
    "Set `random_state` to 1 again when creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=1, splitter='best')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model.\n",
    "# help(iowa_model = DecisionTreeRegressor)\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit iowa_model with the training data.\n",
    "# help(iowa_model.fit)\n",
    "iowa_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Make predictions with Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with all `val_` observation.\n",
    "# help(iowa_model.predict(val_X))\n",
    "forcast = iowa_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186500. 184000. 130000.  92000. 164500. 220000. 335000. 144152. 215000.\n",
      " 262000.]\n",
      "--------------------------------------------------\n",
      "258     231500\n",
      "267     179500\n",
      "288     122000\n",
      "649      84500\n",
      "1233    142000\n",
      "167     325624\n",
      "926     285000\n",
      "831     151000\n",
      "1237    195000\n",
      "426     275000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Inspection the predictions and actual values from validation data.\n",
    "#\n",
    "\n",
    "# print the top few validation predictions.\n",
    "print(forcast[:10])\n",
    "print(50 * \"-\")\n",
    "# print the top few actual prices.\n",
    "print(val_y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the Mean absolutely Error in Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = $29652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# print(dir(sklearn.metrics))\n",
    "# help(mean_absolute_error)\n",
    "\n",
    "val_mae = mean_absolute_error(val_y, forcast)\n",
    "print(f\"MAE = ${int(val_mae)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting\n",
    "\n",
    "I build my model, and now it's time to optimize the size of the tree to make better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error: 35044.51323006062\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error: 27405.9305977479\n",
      "Max leaf nodes: 60  \t\t Mean Absolute Error: 27110.899469831442\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error: 29454.183240959952\n",
      "Max leaf nodes: 900  \t\t Mean Absolute Error: 30016.684474885846\n",
      "Max leaf nodes: 1000  \t\t Mean Absolute Error: 30006.734246575343\n",
      "Max leaf nodes: 1070  \t\t Mean Absolute Error: 30011.569863013698\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [5, 50, 60, 500, 900, 1000, 1070]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(f\"Max leaf nodes: {max_leaf_nodes}  \\t\\t Mean Absolute Error: {my_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the options listed, 500 is the optimal number of leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Here's the takeaway: Models can suffer from either:\n",
    "\n",
    "**Overfitting**: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or  \n",
    "**Underfitting**: failing to capture relevant patterns, again leading to less accurate predictions.  \n",
    "We use **validation** data, which isn't used in model training, to measure a candidate model's accuracy.  \n",
    "This lets us try many candidate models and keep the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
