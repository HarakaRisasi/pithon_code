Мы выяснили, что компьютер понимает только нулики и единички, а его память можно представить в виде ооочень длинной строки из лампочек с выключателями. Как представить цифры в компьютере мы уже поняли. А что делать с остальной информацией? Буквами, картинками?

Скажем, в английском алфавите 26 букв. Теоретически мы можем представить буквы цифрами от 0 до 25, только в двоичной системе. Возникает другой вопрос: а как понять, перед нами строчная буква или прописная? А знаки препинания? Что делать со знаками-«невидимками», вроде пробела? Словом, нужна система кодирования, Кэп!

В 1960-х годах существовало множество разных схем, кодирующих символы. Отсутствие единообразия довольно быстро переросло в серьёзную проблему, и уже в 1963 году Американский институт стандартизации ANSI разработал и ввел в обиход схему кодировки ASCII (American Standard Code for Information Interchange). 

Каждый символ ASCII состоит из семи разрядов или семи бит, каждый из которых может принимать значение 0 или 1. В 7 бит можно поместить числа от 0 до 127 в двоичной системе, то есть у нас есть 128 чисел для кодирования символов. Казалось бы, достаточно для кодировки письменной английской речи? 

Давайте прикинем: 

a-z — 26 вариантов
A-Z — еще 26
0-9 — 10
,;:~& и прочие знаки пунктуации — 32
Ещё нам нужен пробел.
Итого — 95 символов.
Оставшиеся 33 (128 - 95) вакантных варианта используют для так называемых управляющих символов, вроде перевода строки или возврата каретки.


Важно различать символы 0-9 и числовые значения 0-9.
Символы 0-9 представлены значениями ASCII 48-57.
Интересно отметить, что крайние правые четыре бита этих значений ASCII представляют собой двоичные представления числовых значений 0-9. Это несколько упрощает способ преобразования между значениями ASCII и их фактическими числовыми значениями.